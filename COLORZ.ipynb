{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQRonTuKjgOw"
   },
   "source": [
    "# Importing required libraries and infor about dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17198,
     "status": "ok",
     "timestamp": 1730038244625,
     "user": {
      "displayName": "Pushp Raj Panth",
      "userId": "11716724115225908361"
     },
     "user_tz": -330
    },
    "id": "nrtU70BLjl1X"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import BatchNormalization,Dense, Flatten, Dropout\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model,load_model\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy, Precision, Recall\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1730038244626,
     "user": {
      "displayName": "Pushp Raj Panth",
      "userId": "11716724115225908361"
     },
     "user_tz": -330
    },
    "id": "i4lcy240jhfO",
    "outputId": "b49eff5f-6d92-42a5-e242-1787c32a9e92"
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet('category_attributes.parquet')\n",
    "#print(df)\n",
    "attribute_list = df['Attribute_list']\n",
    "for i in range(len(attribute_list)):\n",
    "  print(attribute_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1730038244626,
     "user": {
      "displayName": "Pushp Raj Panth",
      "userId": "11716724115225908361"
     },
     "user_tz": -330
    },
    "id": "WezN9k58jkbM",
    "outputId": "b89005e6-fcd6-426d-abea-1d5c0cc55137"
   },
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Convert 'id' column to string and pad with leading zeros to make each entry 6 digits\n",
    "train_data['id'] = train_data['id'].astype(str).str.zfill(6)\n",
    "print(train_data.head(20))\n",
    "#print(len(train_data))  70213"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating individual dataframe for all category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1561,
     "status": "ok",
     "timestamp": 1730038246185,
     "user": {
      "displayName": "Pushp Raj Panth",
      "userId": "11716724115225908361"
     },
     "user_tz": -330
    },
    "id": "z7W-xd9BjsrQ",
    "outputId": "80fecb4f-3182-4b1d-bbba-bc573b6a40f4"
   },
   "outputs": [],
   "source": [
    "category_dfs = {category: train_data[train_data['Category'] == category] for category in train_data['Category'].unique()}\n",
    "#print(category_dfs)\n",
    "\n",
    "#making dataframes according to categories\n",
    "men_tshirt_df = category_dfs['Men Tshirts']\n",
    "saree_df=category_dfs['Sarees']\n",
    "kurtis_df=category_dfs['Kurtis']\n",
    "women_tshirts_df=category_dfs['Women Tshirts']\n",
    "women_dresses_df=category_dfs['Women Tops & Tunics']\n",
    "\n",
    "\n",
    "#Filtering out empty attributes\n",
    "def filtering_column(df):\n",
    "    empty_cols = [col for col in df.columns if df[col].isnull().all()]\n",
    "    df = df.drop(columns=empty_cols)\n",
    "    df = df.drop(columns=[\"len\"])     # len is number of attributes the data have\n",
    "    return df\n",
    "\n",
    "df_dict = {\n",
    "    'men_tshirt_df': men_tshirt_df,\n",
    "    'saree_df': saree_df,\n",
    "    'kurtis_df': kurtis_df,\n",
    "    'women_tshirts_df': women_tshirts_df,\n",
    "    'women_dresses_df': women_dresses_df\n",
    "}\n",
    "\n",
    "for df_name, df in df_dict.items():\n",
    "    df_dict[df_name] = filtering_column(df)  # Update the dictionary with the filtered DataFrame\n",
    "    #print(df_dict[df_name])  # Print the updated DataFrame\n",
    "\n",
    "# Access the updated DataFrames using their original names\n",
    "men_tshirt_df = df_dict['men_tshirt_df']  #['color' 'neck' 'pattern' 'print_or_pattern_type' 'sleeve_length']\n",
    "saree_df = df_dict['saree_df']      #['blouse_pattern' 'border' 'border_width' 'color' 'occasion' 'ornamentation' 'pallu_details' 'pattern' 'print_or_pattern_type' 'transparency']\n",
    "kurtis_df=df_dict['kurtis_df']      #['color' 'fit_shape' 'length' 'occasion' 'ornamentation' 'pattern' 'print_or_pattern_type' 'sleeve_length' 'sleeve_styling']\n",
    "women_tshirts_df=df_dict['women_tshirts_df']    #['color' 'fit_shape' 'length' 'pattern' 'print_or_pattern_type' 'sleeve_length' 'sleeve_styling' 'surface_styling']\n",
    "women_dresses_df=df_dict['women_dresses_df']    #['color' 'fit_shape' 'length' 'neck_collar' 'ocassion' 'pattern' 'print_or_pattern_type' 'sleeve_length' 'sleeve_styling' 'surface_styling']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCH4V2Gdj4wL"
   },
   "source": [
    "### Removing rows with even one Nan value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=women_dresses_df\n",
    "\n",
    "# Step 1: Define the attribute columns to check\n",
    "attribute_columns = df.columns[2:]\n",
    "\n",
    "# Step 2: Identify rows where more than 3 attributes are NaN\n",
    "rows_to_remove = df[attribute_columns].isna().sum(axis=1) > 3\n",
    "rows_to_remove_indices = df[rows_to_remove].index\n",
    "print(\"Indices of rows with more than 3 'NaN' values:\", rows_to_remove_indices.tolist())\n",
    "\n",
    "# Step 3: Remove those rows from the DataFrame\n",
    "df_cleaned = df[~rows_to_remove]\n",
    "\n",
    "print(\"\\nDataFrame after removing rows with more than 3 'NaN' values:\")\n",
    "print(df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yX5FpVjbkOxB"
   },
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 76086,
     "status": "ok",
     "timestamp": 1730038322268,
     "user": {
      "displayName": "Pushp Raj Panth",
      "userId": "11716724115225908361"
     },
     "user_tz": -330
    },
    "id": "tuR8Rn0UkL-7"
   },
   "outputs": [],
   "source": [
    "df = df_cleaned\n",
    "# Set up paths and output directory\n",
    "input_folder = \"train_images\"\n",
    "augmented_folder = \"augmented_folder\"\n",
    "os.makedirs(augmented_folder, exist_ok=True)\n",
    "\n",
    "# Initialize the data generator with augmentation options\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "# Load your DataFrame\n",
    "\n",
    "attribute_columns = df.columns[2:]  # Adjust if 'id' and 'category' are the first two columns\n",
    "\n",
    "# Create a list to store augmented data entries\n",
    "augmented_data = []\n",
    "\n",
    "# Loop through each image in the DataFrame\n",
    "for idx, row in df.iterrows():\n",
    "    img_id = row['id']\n",
    "    img_path = os.path.join(input_folder, f\"{img_id}.jpg\")\n",
    "\n",
    "    # Load image and resize for consistency\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"Image {img_id} not found, skipping.\")\n",
    "        continue\n",
    "    img = cv2.resize(img, (224, 224))  # Resize if needed for model input\n",
    "\n",
    "    # Copy the original image to the augmented folder\n",
    "    original_img_path = os.path.join(augmented_folder, f\"{img_id}.jpg\")\n",
    "    shutil.copy(img_path, original_img_path)\n",
    "\n",
    "    # Append original image info to augmented data list\n",
    "    original_row = row.copy()\n",
    "    augmented_data.append(original_row)\n",
    "\n",
    "    # Reshape to add batch dimension (needed for ImageDataGenerator)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    # Generate 3 augmented images per original image\n",
    "    aug_iter = datagen.flow(img, batch_size=1)\n",
    "    for i in range(2):\n",
    "        # Generate augmented image and remove batch dimension\n",
    "        aug_img = next(aug_iter)[0].astype(np.uint8)\n",
    "\n",
    "        # Create a unique filename for the augmented image\n",
    "        aug_img_id = f\"{img_id}_aug_{i+1}\"\n",
    "        aug_img_path = os.path.join(augmented_folder, f\"{aug_img_id}.jpg\")\n",
    "\n",
    "        # Save the augmented image\n",
    "        cv2.imwrite(aug_img_path, aug_img)\n",
    "\n",
    "        # Append the new image info to the augmented data list\n",
    "        augmented_row = row.copy()\n",
    "        augmented_row['id'] = aug_img_id\n",
    "        augmented_data.append(augmented_row)\n",
    "\n",
    "# Convert augmented data list to a DataFrame and append to original DataFrame\n",
    "df_augmented = pd.DataFrame(augmented_data, columns=df.columns)\n",
    "#df_augmented.to_csv(\"augmented_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "for img_id in df_augmented['id']:\n",
    "    img_path = f\"augmented_folder/{img_id}.jpg\"  # Ensure path and extension match your files\n",
    "    img = cv2.imread(img_path)\n",
    "    #print(img)\n",
    "    if img is None:\n",
    "        print(f\"Image with ID {img_id} not found at {img_path}\")\n",
    "        continue  # Skip to the next image if this one is missing\n",
    "    img = cv2.resize(img, (224, 224))  # Resize to 224x224 for most image models\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # doing this because of cv2.imread\n",
    "    img = img / 255.0  # Normalize pixel values\n",
    "\n",
    "    images.append(img)\n",
    "    print(\"Resizing\")\n",
    "\n",
    "X_images = np.array(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_columns=df_cleaned.columns[2:]\n",
    "# Assuming you have the final DataFrame with one-hot encoded attributes\n",
    "# Split the DataFrame into features and labels\n",
    "# 'id' is usually not used as a feature, and you should only include your one-hot encoded attributes as labels\n",
    "y_label = df_augmented[attribute_columns]  # This will contain all the one-hot encoded columns\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_images, y_label, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"X Training set size: {X_train.shape[0]}\")\n",
    "print(f\"X Testing set size: {X_test.shape[0]}\")\n",
    "print(f\"Y Training set size: {y_train.shape[0]}\")\n",
    "print(f\"Y Testing set size: {y_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9aG2vFgNrjYX"
   },
   "source": [
    "## Onehot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1730038322268,
     "user": {
      "displayName": "Pushp Raj Panth",
      "userId": "11716724115225908361"
     },
     "user_tz": -330
    },
    "id": "GiDTswltqGKs",
    "outputId": "13571bc4-319d-4dc9-c322-9b273397bada"
   },
   "outputs": [],
   "source": [
    "df=y_label\n",
    "num_classes_attr1 = len(df['attr_1'].unique())\n",
    "num_classes_attr2 = len(df['attr_2'].unique())\n",
    "num_classes_attr3 = len(df['attr_3'].unique())\n",
    "num_classes_attr4 = len(df['attr_4'].unique())\n",
    "num_classes_attr5 = len(df['attr_5'].unique())\n",
    "num_classes_attr6 = len(df['attr_6'].unique())\n",
    "num_classes_attr7 = len(df['attr_7'].unique())\n",
    "num_classes_attr8 = len(df['attr_8'].unique())\n",
    "num_classes_attr9 = len(df['attr_9'].unique())\n",
    "num_classes_attr10 = len(df['attr_10'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_classes_attr1)\n",
    "print(num_classes_attr2)\n",
    "print(num_classes_attr3)\n",
    "print(num_classes_attr4)\n",
    "print(num_classes_attr5)\n",
    "print(num_classes_attr6)\n",
    "print(num_classes_attr7)\n",
    "print(num_classes_attr8)\n",
    "print(num_classes_attr9)\n",
    "#print(num_classes_attr10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate encoders for each attribute\n",
    "encoder1 = OneHotEncoder(sparse_output=False)\n",
    "encoder2 = OneHotEncoder(sparse_output=False)\n",
    "encoder3 = OneHotEncoder(sparse_output=False)\n",
    "encoder4 = OneHotEncoder(sparse_output=False)\n",
    "encoder5 = OneHotEncoder(sparse_output=False)\n",
    "encoder6 = OneHotEncoder(sparse_output=False)\n",
    "encoder7 = OneHotEncoder(sparse_output=False)\n",
    "encoder8 = OneHotEncoder(sparse_output=False)\n",
    "encoder9 = OneHotEncoder(sparse_output=False)\n",
    "encoder10 = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Encode each attribute with its own encoder for training data\n",
    "y_train_attr1 = encoder1.fit_transform(y_train['attr_1'].values.reshape(-1, 1))\n",
    "y_train_attr2 = encoder2.fit_transform(y_train['attr_2'].values.reshape(-1, 1))\n",
    "y_train_attr3 = encoder3.fit_transform(y_train['attr_3'].values.reshape(-1, 1))\n",
    "y_train_attr4 = encoder4.fit_transform(y_train['attr_4'].values.reshape(-1, 1))\n",
    "y_train_attr5 = encoder5.fit_transform(y_train['attr_5'].values.reshape(-1, 1))\n",
    "y_train_attr6 = encoder6.fit_transform(y_train['attr_6'].values.reshape(-1, 1))\n",
    "y_train_attr7 = encoder7.fit_transform(y_train['attr_7'].values.reshape(-1, 1))\n",
    "y_train_attr8 = encoder8.fit_transform(y_train['attr_8'].values.reshape(-1, 1))\n",
    "y_train_attr9 = encoder9.fit_transform(y_train['attr_9'].values.reshape(-1, 1))\n",
    "y_train_attr10 = encoder10.fit_transform(y_train['attr_10'].values.reshape(-1, 1))\n",
    "\n",
    "# Do the same for test data using the fitted encoders (use transform, not fit_transform)\n",
    "y_test_attr1 = encoder1.transform(y_test['attr_1'].values.reshape(-1, 1))\n",
    "y_test_attr2 = encoder2.transform(y_test['attr_2'].values.reshape(-1, 1))\n",
    "y_test_attr3 = encoder3.transform(y_test['attr_3'].values.reshape(-1, 1))\n",
    "y_test_attr4 = encoder4.transform(y_test['attr_4'].values.reshape(-1, 1))\n",
    "y_test_attr5 = encoder5.transform(y_test['attr_5'].values.reshape(-1, 1))\n",
    "y_test_attr6 = encoder6.transform(y_test['attr_6'].values.reshape(-1, 1))\n",
    "y_test_attr7 = encoder7.transform(y_test['attr_7'].values.reshape(-1, 1))\n",
    "y_test_attr8 = encoder8.transform(y_test['attr_8'].values.reshape(-1, 1))\n",
    "y_test_attr9 = encoder9.transform(y_test['attr_9'].values.reshape(-1, 1))\n",
    "y_test_attr10 = encoder10.transform(y_test['attr_10'].values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_train_attr1))\n",
    "print(len(y_train_attr1[0]))\n",
    "\n",
    "print(len(y_train_attr2))\n",
    "print(len(y_train_attr2[0]))\n",
    "\n",
    "print(len(y_train_attr3))\n",
    "print(len(y_train_attr3[0]))\n",
    "\n",
    "print(len(y_train_attr4))\n",
    "print(len(y_train_attr4[0]))\n",
    "\n",
    "print(len(y_train_attr5))\n",
    "print(len(y_train_attr5[0]))\n",
    "\n",
    "print(len(y_train_attr6))\n",
    "print(len(y_train_attr6[0]))\n",
    "\n",
    "print(len(y_train_attr7))\n",
    "print(len(y_train_attr7[0]))\n",
    "\n",
    "print(len(y_train_attr8))\n",
    "print(len(y_train_attr8[0]))\n",
    "\n",
    "\"\"\"print(len(y_train_attr9))\n",
    "print(len(y_train_attr9[0]))\"\"\"\n",
    "\n",
    "\"\"\"print(len(y_train_attr10))\n",
    "print(len(y_train_attr10[0]))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_test_attr1))\n",
    "print(len(y_test_attr1[0]))\n",
    "\n",
    "print(len(y_test_attr2))\n",
    "print(len(y_test_attr2[0]))\n",
    "\n",
    "print(len(y_test_attr3))\n",
    "print(len(y_test_attr3[0]))\n",
    "\n",
    "print(len(y_test_attr4))\n",
    "print(len(y_test_attr4[0]))\n",
    "\n",
    "print(len(y_test_attr5))\n",
    "print(len(y_test_attr5[0]))\n",
    "\n",
    "print(len(y_test_attr6))\n",
    "print(len(y_test_attr6[0]))\n",
    "\n",
    "print(len(y_test_attr7))\n",
    "print(len(y_test_attr7[0]))\n",
    "\n",
    "print(len(y_test_attr8))\n",
    "print(len(y_test_attr8[0]))\n",
    "\n",
    "\"\"\"print(len(y_test_attr9))\n",
    "print(len(y_test_attr9[0]))\"\"\"\n",
    "\n",
    "\"\"\"print(len(y_test_attr10))\n",
    "print(len(y_test_attr10[0]))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5Yxb4CPNVCz"
   },
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base model\n",
    "weights_path = os.path.abspath('resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "base_model = ResNet50(weights=weights_path, include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Flatten the output of base model\n",
    "x = Flatten()(base_model.output)\n",
    "\n",
    "# Add a fully connected layer\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "\n",
    "# Add separate output layers for each attribute\n",
    "output_attr1 = Dense(num_classes_attr1, activation='softmax', name='output_1')(x)\n",
    "output_attr2 = Dense(num_classes_attr2, activation='softmax', name='output_2')(x)\n",
    "output_attr3 = Dense(num_classes_attr3, activation='softmax', name='output_3')(x)\n",
    "output_attr4 = Dense(num_classes_attr4, activation='softmax', name='output_4')(x)\n",
    "output_attr5 = Dense(num_classes_attr5, activation='softmax', name='output_5')(x)\n",
    "output_attr6 = Dense(num_classes_attr6, activation='softmax', name='output_6')(x)\n",
    "output_attr7 = Dense(num_classes_attr7, activation='softmax', name='output_7')(x)\n",
    "output_attr8 = Dense(num_classes_attr8, activation='softmax', name='output_8')(x)\n",
    "output_attr9 = Dense(num_classes_attr9, activation='softmax', name='output_9')(x)\n",
    "output_attr10 = Dense(num_classes_attr10, activation='softmax', name='output_10')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_attr1)\n",
    "print(output_attr2)\n",
    "print(output_attr3)\n",
    "print(output_attr4)\n",
    "print(output_attr5)\n",
    "print(output_attr6)\n",
    "print(output_attr7)\n",
    "print(output_attr8)\n",
    "print(output_attr9)\n",
    "#print(output_attr10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's be explicit about the model outputs\n",
    "outputs = {\n",
    "    'output_1': output_attr1,\n",
    "    'output_2': output_attr2,\n",
    "    'output_3': output_attr3,\n",
    "    'output_4': output_attr4,\n",
    "    'output_5': output_attr5,\n",
    "    'output_6': output_attr6,\n",
    "    'output_7': output_attr7,\n",
    "    'output_8': output_attr8,\n",
    "    'output_9': output_attr9,\n",
    "    'output_10': output_attr10\n",
    "\n",
    "}\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "# Freeze early layers but unfreeze some top layers\n",
    "for layer in base_model.layers[:-30]:  # Unfreeze last 30 layers\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "# Then modify the compile section to match these output names\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss={\n",
    "        'output_1': 'categorical_crossentropy',\n",
    "        'output_2': 'categorical_crossentropy',\n",
    "        'output_3': 'categorical_crossentropy',\n",
    "        'output_4': 'categorical_crossentropy',\n",
    "        'output_5': 'categorical_crossentropy',\n",
    "        'output_6': 'categorical_crossentropy',\n",
    "        'output_7': 'categorical_crossentropy',\n",
    "        'output_8': 'categorical_crossentropy',\n",
    "        'output_9': 'categorical_crossentropy',\n",
    "        'output_10': 'categorical_crossentropy'\n",
    "    },\n",
    "    metrics={\n",
    "        'output_1': [CategoricalAccuracy(), Precision(), Recall()],\n",
    "        'output_2': [CategoricalAccuracy(), Precision(), Recall()],\n",
    "        'output_3': [CategoricalAccuracy(), Precision(), Recall()],\n",
    "        'output_4': [CategoricalAccuracy(), Precision(), Recall()],\n",
    "        'output_5': [CategoricalAccuracy(), Precision(), Recall()],\n",
    "        'output_6': [CategoricalAccuracy(), Precision(), Recall()],\n",
    "        'output_7': [CategoricalAccuracy(), Precision(), Recall()],\n",
    "        'output_8': [CategoricalAccuracy(), Precision(), Recall()],\n",
    "        'output_9': [CategoricalAccuracy(), Precision(), Recall()],\n",
    "        'output_10': [CategoricalAccuracy(), Precision(), Recall()]\n",
    "    }\n",
    ")\n",
    "\n",
    "# And modify the fit to use these same names\n",
    "history1 = model.fit(\n",
    "    X_train,\n",
    "    {\n",
    "        'output_1': y_train_attr1,\n",
    "        'output_2': y_train_attr2,\n",
    "        'output_3': y_train_attr3,\n",
    "        'output_4': y_train_attr4,\n",
    "        'output_5': y_train_attr5,\n",
    "        'output_6': y_train_attr6,\n",
    "        'output_7': y_train_attr7,\n",
    "        'output_8': y_train_attr8,\n",
    "        'output_9': y_train_attr9,\n",
    "        'output_10': y_train_attr10\n",
    "    },\n",
    "    validation_data=(X_test, {\n",
    "        'output_1': y_test_attr1,\n",
    "        'output_2': y_test_attr2,\n",
    "        'output_3': y_test_attr3,\n",
    "        'output_4': y_test_attr4,\n",
    "        'output_5': y_test_attr5,\n",
    "        'output_6': y_test_attr6,\n",
    "        'output_7': y_test_attr7,\n",
    "        'output_8': y_test_attr8,\n",
    "        'output_9': y_test_attr9,\n",
    "        'output_10': y_test_attr10\n",
    "    }),\n",
    "    epochs=12,\n",
    "    batch_size=35\n",
    ")\n",
    "\n",
    "# Phase 2: Fine-tune by unfreezing last 30 layers\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.00001),\n",
    "    loss={\n",
    "        'output_1': 'categorical_crossentropy',\n",
    "        'output_2': 'categorical_crossentropy',\n",
    "        'output_3': 'categorical_crossentropy',\n",
    "        'output_4': 'categorical_crossentropy',\n",
    "        'output_5': 'categorical_crossentropy',\n",
    "        'output_6': 'categorical_crossentropy',\n",
    "        'output_7': 'categorical_crossentropy',\n",
    "        'output_8': 'categorical_crossentropy',\n",
    "        'output_9': 'categorical_crossentropy',\n",
    "        'output_10': 'categorical_crossentropy'\n",
    "    },\n",
    "    metrics={\n",
    "        'output_1': [CategoricalAccuracy(), Precision(), Recall()],\n",
    "        'output_2': [CategoricalAccuracy(), Precision(), Recall()],\n",
    "        'output_3': [CategoricalAccuracy(), Precision(), Recall()],\n",
    "        'output_4': [CategoricalAccuracy(), Precision(), Recall()],\n",
    "        'output_5': [CategoricalAccuracy(), Precision(), Recall()],\n",
    "        'output_6': [CategoricalAccuracy(), Precision(), Recall()],\n",
    "        'output_7': [CategoricalAccuracy(), Precision(), Recall()],\n",
    "        'output_8': [CategoricalAccuracy(), Precision(), Recall()],\n",
    "        'output_9': [CategoricalAccuracy(), Precision(), Recall()],\n",
    "        'output_10': [CategoricalAccuracy(), Precision(), Recall()]\n",
    "    }\n",
    ")\n",
    "\n",
    "# And modify the fit to use these same names\n",
    "history2 = model.fit(\n",
    "    X_train,\n",
    "    {\n",
    "        'output_1': y_train_attr1,\n",
    "        'output_2': y_train_attr2,\n",
    "        'output_3': y_train_attr3,\n",
    "        'output_4': y_train_attr4,\n",
    "        'output_5': y_train_attr5,\n",
    "        'output_6': y_train_attr6,\n",
    "        'output_7': y_train_attr7,\n",
    "        'output_8': y_train_attr8,\n",
    "        'output_9': y_train_attr9,\n",
    "        'output_10': y_train_attr10\n",
    "    },\n",
    "    validation_data=(X_test, {\n",
    "        'output_1': y_test_attr1,\n",
    "        'output_2': y_test_attr2,\n",
    "        'output_3': y_test_attr3,\n",
    "        'output_4': y_test_attr4,\n",
    "        'output_5': y_test_attr5,\n",
    "        'output_6': y_test_attr6,\n",
    "        'output_7': y_test_attr7,\n",
    "        'output_8': y_test_attr8,\n",
    "        'output_9': y_test_attr9,\n",
    "        'output_10': y_test_attr10\n",
    "    }),\n",
    "    epochs=8,\n",
    "    batch_size=35\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_save(model,name):\n",
    "    \"\"\"\n",
    "    Saves the trained model and the corresponding training labels to disk.\n",
    "\n",
    "    Args:\n",
    "        model (Model): Keras model to be saved.\n",
    "        y_train (pd.DataFrame): DataFrame containing the training labels.\n",
    "        name (str): Name suffix to use for saving the model and labels.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    model.save(f'model_{name}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save(model,\"women_dresses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on test images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i) for single image (other than mn tshirt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import re\n",
    "\n",
    "# Assuming kurtis_df is already loaded\n",
    "# Initialize separate encoders for each attribute\n",
    "encoder_attr1 = OneHotEncoder(sparse_output=False)\n",
    "encoder_attr2 = OneHotEncoder(sparse_output=False)\n",
    "encoder_attr3 = OneHotEncoder(sparse_output=False)\n",
    "encoder_attr4 = OneHotEncoder(sparse_output=False)\n",
    "encoder_attr5 = OneHotEncoder(sparse_output=False)\n",
    "encoder_attr6 = OneHotEncoder(sparse_output=False)\n",
    "encoder_attr7 = OneHotEncoder(sparse_output=False)\n",
    "encoder_attr8 = OneHotEncoder(sparse_output=False)\n",
    "\"\"\"encoder_attr9 = OneHotEncoder(sparse_output=False)\n",
    "encoder_attr10 = OneHotEncoder(sparse_output=False)\"\"\"\n",
    "df=women_tshirts_df\n",
    "# Fit each encoder to its respective attribute column in the training data\n",
    "encoder_attr1.fit(df['attr_1'].values.reshape(-1, 1))\n",
    "encoder_attr2.fit(df['attr_2'].values.reshape(-1, 1))\n",
    "encoder_attr3.fit(df['attr_3'].values.reshape(-1, 1))\n",
    "encoder_attr4.fit(df['attr_4'].values.reshape(-1, 1))\n",
    "encoder_attr5.fit(df['attr_5'].values.reshape(-1, 1))\n",
    "encoder_attr6.fit(df['attr_6'].values.reshape(-1, 1))\n",
    "encoder_attr7.fit(df['attr_7'].values.reshape(-1, 1))\n",
    "encoder_attr8.fit(df['attr_8'].values.reshape(-1, 1))\n",
    "\"\"\"encoder_attr9.fit(df['attr_9'].values.reshape(-1, 1))\n",
    "encoder_attr10.fit(df['attr_10'].values.reshape(-1, 1))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the image for prediction\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)  # Load image\n",
    "    img = cv2.resize(img, (224, 224))  # Resize to match model input\n",
    "    img = img.astype(np.float32) / 255.0  # Normalize to float32\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    return img\n",
    "\n",
    "# Load the model\n",
    "model = load_model('model_women_tshirts.keras')  # Replace with your actual model path\n",
    "\n",
    "# Load an image and preprocess it\n",
    "image_path = \"test_images/015324.jpg\"  # Change to your image path\n",
    "preprocessed_image = preprocess_image(image_path)\n",
    "\n",
    "# Make predictions for each attribute's output layer\n",
    "predictions = model.predict(preprocessed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attribute names using feature names from each encoder\n",
    "attribute_names = {\n",
    "    'attr1': encoder_attr1.get_feature_names_out(['attr1']),\n",
    "    'attr2': encoder_attr2.get_feature_names_out(['attr2']),\n",
    "    'attr3': encoder_attr3.get_feature_names_out(['attr3']),\n",
    "    'attr4': encoder_attr4.get_feature_names_out(['attr4']),\n",
    "    'attr5': encoder_attr5.get_feature_names_out(['attr5']),\n",
    "    'attr6': encoder_attr6.get_feature_names_out(['attr6']),\n",
    "    'attr7': encoder_attr7.get_feature_names_out(['attr7']),\n",
    "    'attr8': encoder_attr8.get_feature_names_out(['attr8'])\n",
    "}\n",
    "\n",
    "# Decode predictions for each attribute\n",
    "predicted_labels = []\n",
    "for i, (output_name, attribute_prediction) in enumerate(predictions.items()):\n",
    "    feature_names = attribute_names[f'attr{i+1}']  # Get the corresponding feature names for the attribute\n",
    "    predicted_class_index = np.argmax(attribute_prediction)  # Get index of highest probability\n",
    "    predicted_class_name = feature_names[predicted_class_index]  # Map index to class name\n",
    "    predicted_labels.append(predicted_class_name)\n",
    "\n",
    "# Output the predicted attributes\n",
    "print(\"Predicted attributes:\", predicted_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii) for batch of images (except men tshirt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images_batch(image_paths):\n",
    "    \"\"\"\n",
    "    Preprocess multiple images at once for batch prediction\n",
    "    \n",
    "    Args:\n",
    "        image_paths (list): List of paths to images\n",
    "        \n",
    "    Returns:\n",
    "        np.array: Batch of preprocessed images\n",
    "    \"\"\"\n",
    "    processed_images = []\n",
    "    for image_path in image_paths:\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Could not load image: {image_path}\")\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        processed_images.append(img)\n",
    "    \n",
    "    return np.array(processed_images)\n",
    "\n",
    "def predict_batch(model, image_paths) :\n",
    "    \"\"\"\n",
    "    Make predictions for a batch of images\n",
    "    \n",
    "    Args:\n",
    "        model: Loaded Keras model\n",
    "        image_paths (list): List of image paths\n",
    "        attribute_names (dict): Dictionary mapping attribute names to encoder feature names\n",
    "        \n",
    "    Returns:\n",
    "        list: List of predictions for each image\n",
    "    \"\"\"\n",
    "    # Preprocess all images\n",
    "    batch_images = preprocess_images_batch(image_paths)\n",
    "    \n",
    "    # Get predictions for all images at once\n",
    "    batch_predictions = model.predict(batch_images)\n",
    "    \n",
    "    return batch_predictions\n",
    "\n",
    "\n",
    "\n",
    "def remove_attr_prefix(predicted_labels):\n",
    "    \"\"\"\n",
    "    Remove the 'attrn_' prefix (where n is a number) from all predicted labels and\n",
    "    replace 'default_n' (where n is a number from 1 to 10) with 'default'.\n",
    "    \n",
    "    Args:\n",
    "        predicted_labels (list): List of predicted labels.\n",
    "        \n",
    "    Returns:\n",
    "        list: Filtered list with 'attrn_' prefix removed and 'default_n' replaced with 'default'.\n",
    "    \"\"\"\n",
    "    cleaned_labels = []\n",
    "    for label in predicted_labels:\n",
    "        # Replace 'default_n' (where n is 1-10) with 'default'\n",
    "        label = re.sub(r'default_\\d{1,2}', 'default', label)\n",
    "        # Remove 'attrn_' prefix (where n is any number)\n",
    "        label = re.sub(r'^attr\\d+_', '', label)\n",
    "        cleaned_labels.append(label)\n",
    "    \n",
    "    return cleaned_labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and prepare test data\n",
    "test_data = pd.read_csv(\"Women Tshirts_test_data.csv\")\n",
    "test_data['id'] = test_data['id'].astype(str).str.zfill(6)\n",
    "\n",
    "image_paths = [f\"test_images/{id}.jpg\" for id in test_data['id']]\n",
    "batch_images = preprocess_images_batch(image_paths)\n",
    "model = load_model('model_women_tshirts.keras')\n",
    "attribute_names = {\n",
    "    'attr1': encoder_attr1.get_feature_names_out(['attr1']),\n",
    "    'attr2': encoder_attr2.get_feature_names_out(['attr2']),\n",
    "    'attr3': encoder_attr3.get_feature_names_out(['attr3']),\n",
    "    'attr4': encoder_attr4.get_feature_names_out(['attr4']),\n",
    "    'attr5': encoder_attr5.get_feature_names_out(['attr5']),\n",
    "    'attr6': encoder_attr6.get_feature_names_out(['attr6']),\n",
    "    'attr7': encoder_attr7.get_feature_names_out(['attr7']),\n",
    "    'attr8': encoder_attr8.get_feature_names_out(['attr8'])\n",
    "}\n",
    "\n",
    "# Get predictions for all images at once\n",
    "batch_predictions = predict_batch(model, image_paths)\n",
    "key_list = list(batch_predictions.keys())\n",
    "\n",
    "# Get all predictions at once using vectorized operations\n",
    "predictions = {k: np.argmax(batch_predictions[k], axis=1) for k in key_list}\n",
    "\n",
    "# Pre-calculate feature names mapping\n",
    "feature_names_mapping = {\n",
    "    f'attr{i+1}': attribute_names[f'attr{i+1}']\n",
    "    for i in range(len(key_list))\n",
    "}\n",
    "\n",
    "# Process all images in the batch and update test_data\n",
    "for batch_idx, img_id in enumerate(test_data['id']):\n",
    "    # Get predictions for all attributes for current image\n",
    "    current_predictions = []\n",
    "    for i, k in enumerate(key_list):\n",
    "        pred_idx = predictions[k][batch_idx]\n",
    "        feature_names = feature_names_mapping[f'attr{i+1}']\n",
    "        current_predictions.append(feature_names[pred_idx])\n",
    "    \n",
    "    # Clean the predictions\n",
    "    cleaned_pred = remove_attr_prefix(current_predictions)\n",
    "    \n",
    "    # Ensure exactly 10 entries (padding with dummy_value if needed)\n",
    "    cleaned_pred += [\"dummy_value\"] * (10 - len(cleaned_pred))\n",
    "    \n",
    "    # Update the DataFrame for the current image\n",
    "    test_data.loc[test_data['id'] == img_id, \n",
    "                 [\"attr_1\", \"attr_2\", \"attr_3\", \"attr_4\", \"attr_5\",\n",
    "                  \"attr_6\", \"attr_7\", \"attr_8\", \"attr_9\", \"attr_10\"]] = cleaned_pred\n",
    "    \n",
    "    print(f\"Image {img_id} predictions:\", cleaned_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii) Code for single image (men tshirt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Initialize separate encoders for each attribute\n",
    "encoder_attr1 = OneHotEncoder(sparse_output=False)\n",
    "encoder_attr2 = OneHotEncoder(sparse_output=False)\n",
    "encoder_attr3 = OneHotEncoder(sparse_output=False)\n",
    "encoder_attr4 = OneHotEncoder(sparse_output=False)\n",
    "encoder_attr5 = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "df=men_tshirt_df\n",
    "# Fit each encoder to its respective attribute column in the training data\n",
    "encoder_attr1.fit(df['attr_1'].values.reshape(-1, 1))\n",
    "encoder_attr2.fit(df['attr_2'].values.reshape(-1, 1))\n",
    "encoder_attr3.fit(df['attr_3'].values.reshape(-1, 1))\n",
    "encoder_attr4.fit(df['attr_4'].values.reshape(-1, 1))\n",
    "encoder_attr5.fit(df['attr_5'].values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the image for prediction\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)  # Load image\n",
    "    img = cv2.resize(img, (224, 224))  # Resize to match model input\n",
    "    img = img.astype(np.float32) / 255.0  # Normalize to float32\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    return img\n",
    "\n",
    "# Load the model\n",
    "model = load_model('model_men_tshirt.keras')  # Replace with your actual model path\n",
    "\n",
    "# Load an image and preprocess it\n",
    "image_path = \"test_images/000196.jpg\"  # Change to your image path\n",
    "preprocessed_image = preprocess_image(image_path)\n",
    "\n",
    "# Make predictions for each attribute's output layer\n",
    "predictions = model.predict(preprocessed_image)\n",
    "\n",
    "# Attribute names using feature names from each encoder\n",
    "attribute_names = {\n",
    "    'attr1': encoder_attr1.get_feature_names_out(['attr1']),\n",
    "    'attr2': encoder_attr2.get_feature_names_out(['attr2']),\n",
    "    'attr3': encoder_attr3.get_feature_names_out(['attr3']),\n",
    "    'attr4': encoder_attr4.get_feature_names_out(['attr4']),\n",
    "    'attr5': encoder_attr5.get_feature_names_out(['attr5'])\n",
    "}\n",
    "# Decode predictions for each attribute\n",
    "predicted_labels = []\n",
    "for i, (attr_name, feature_names) in enumerate(attribute_names.items()):\n",
    "    attribute_prediction = predictions[i]  # Prediction for the current attribute\n",
    "    predicted_class_index = np.argmax(attribute_prediction)  # Get index of highest probability\n",
    "    predicted_class_name = feature_names[predicted_class_index]  # Map index to class name\n",
    "    predicted_labels.append(predicted_class_name)\n",
    "\n",
    "# Output the predicted attributes\n",
    "print(\"Predicted attributes:\", predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv) Test for batch of images (for men tshirt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_images_batch(image_paths):\n",
    "    \"\"\"\n",
    "    Preprocess multiple images at once for batch prediction\n",
    "    \n",
    "    Args:\n",
    "        image_paths (list): List of paths to images\n",
    "        \n",
    "    Returns:\n",
    "        np.array: Batch of preprocessed images\n",
    "    \"\"\"\n",
    "    processed_images = []\n",
    "    for image_path in image_paths:\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Could not load image: {image_path}\")\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        processed_images.append(img)\n",
    "    \n",
    "    return np.array(processed_images)\n",
    "\n",
    "def clean_prediction_labels(predictions):\n",
    "    \"\"\"\n",
    "    Remove 'attrn_' prefix from prediction labels in a nested list.\n",
    "    \n",
    "    Args:\n",
    "        predictions (list of list): List of lists where each inner list contains prediction labels with 'attrn_' prefix.\n",
    "        \n",
    "    Returns:\n",
    "        list of list: Cleaned prediction labels in the same nested list structure.\n",
    "    \"\"\"\n",
    "    cleaned_predictions = []\n",
    "    for pred_list in predictions:\n",
    "        cleaned_pred_list = []\n",
    "        for pred in pred_list:\n",
    "            # Replace 'attrn_default_n' with 'default'\n",
    "            if re.match(r'attr\\d+_default_\\d+', pred):\n",
    "                cleaned_pred_list.append(\"default\")\n",
    "            else:\n",
    "                # Remove prefix 'attrn_'\n",
    "                cleaned_pred_list.append(re.sub(r'attr\\d+_', '', pred))\n",
    "        cleaned_predictions.append(cleaned_pred_list)\n",
    "    \n",
    "    return cleaned_predictions\n",
    "\n",
    "\n",
    "\n",
    "def predict_batch(model, image_paths, attribute_names):\n",
    "    \"\"\"\n",
    "    Make predictions for a batch of images\n",
    "    \n",
    "    Args:\n",
    "        model: Loaded Keras model\n",
    "        image_paths (list): List of image paths\n",
    "        attribute_names (dict): Dictionary mapping attribute names to encoder feature names\n",
    "        \n",
    "    Returns:\n",
    "        list: List of predictions for each image\n",
    "    \"\"\"\n",
    "    # Preprocess all images\n",
    "    batch_images = preprocess_images_batch(image_paths)\n",
    "    \n",
    "    # Get predictions for all images at once\n",
    "    batch_predictions = model.predict(batch_images)\n",
    "    \n",
    "    # Process predictions for all images\n",
    "    all_predictions = []\n",
    "    num_images = len(image_paths)\n",
    "    \n",
    "    # If model outputs a list of predictions (one per attribute)\n",
    "    if isinstance(batch_predictions, list):\n",
    "        for img_idx in range(num_images):\n",
    "            image_predictions = []\n",
    "            for attr_idx, (attr_name, feature_names) in enumerate(attribute_names.items()):\n",
    "                prediction = batch_predictions[attr_idx][img_idx]\n",
    "                predicted_class_index = np.argmax(prediction)\n",
    "                predicted_class_name = feature_names[predicted_class_index]\n",
    "                image_predictions.append(predicted_class_name)\n",
    "            all_predictions.append(image_predictions)\n",
    "    else:\n",
    "        # If model outputs a single array\n",
    "        for img_idx in range(num_images):\n",
    "            image_predictions = []\n",
    "            for attr_idx, (attr_name, feature_names) in enumerate(attribute_names.items()):\n",
    "                prediction = batch_predictions[img_idx][attr_idx]\n",
    "                predicted_class_index = np.argmax(prediction)\n",
    "                predicted_class_name = feature_names[predicted_class_index]\n",
    "                image_predictions.append(predicted_class_name)\n",
    "            all_predictions.append(image_predictions)\n",
    "    \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = load_model('model_men_tshirt.keras')\n",
    "\n",
    "# Process test data\n",
    "test_data = pd.read_csv(\"Men Tshirts_test_data.csv\")\n",
    "test_data['id'] = test_data['id'].astype(str).str.zfill(6)\n",
    "\n",
    "# Create list of image paths\n",
    "image_paths = [f\"test_images/{id}.jpg\" for id in test_data['id']]\n",
    "\n",
    "# Attribute names using feature names from each encoder\n",
    "attribute_names = {\n",
    "    'attr1': encoder_attr1.get_feature_names_out(['attr1']),\n",
    "    'attr2': encoder_attr2.get_feature_names_out(['attr2']),\n",
    "    'attr3': encoder_attr3.get_feature_names_out(['attr3']),\n",
    "    'attr4': encoder_attr4.get_feature_names_out(['attr4']),\n",
    "    'attr5': encoder_attr5.get_feature_names_out(['attr5'])\n",
    "}\n",
    "\n",
    "# Get predictions for all images at once\n",
    "predictions = predict_batch(model, image_paths, attribute_names)\n",
    "\n",
    "for img_id, pred in zip(test_data['id'], predictions):\n",
    "    # Clean the current prediction list\n",
    "    cleaned_pred = clean_prediction_labels([pred])[0]  # Get the cleaned inner list for this image\n",
    "    \n",
    "    # Ensure the cleaned_pred list has exactly 10 entries (adding 'dummy_value' as needed)\n",
    "    cleaned_pred += [\"dummy_value\"] * (10 - len(cleaned_pred))\n",
    "    \n",
    "    # Locate the row for the current img_id and assign the cleaned predictions\n",
    "    test_data.loc[test_data['id'] == img_id, [\"attr_1\", \"attr_2\", \"attr_3\", \"attr_4\", \"attr_5\", \n",
    "                                              \"attr_6\", \"attr_7\", \"attr_8\", \"attr_9\", \"attr_10\"]] = cleaned_pred\n",
    "    \n",
    "    print(f\"Image {img_id} predictions:\", cleaned_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"test_data.to_csv(\"predictions.csv\",index=False)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([data, test_data], ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(\"predictions.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPWrPt/xcS94oW2v56w4yn+",
   "gpuType": "T4",
   "mount_file_id": "1oTiBKALqGJYbL7QQbAQyjOFW1_FvC3CV",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
